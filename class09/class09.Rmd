---
title: 'Class 9: Analysis of Human Breast Cancer Cells'
author: "Enrique Sandoval"
date: "4/30/2019"
output: github_document
---

```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
head(wisc.df)
```

#Converting into matrix 
```{r}
wisc.data <-as.matrix(wisc.df[,3:32])
row.names(wisc.data) <- wisc.df$id
head(wisc.data)
```

#Diagnosis vector stored as vecotr of 1 and 0
```{r}
diagnosis<- as.numeric(wisc.df$diagnosis =="M")
```


Q1. How many patients 
```{r}
nrow(wisc.df)
```

Q2. How many variables/ features in data suffixed with mean 
```{r}
length(grep("_mean",colnames(wisc.data)))

```


Q3. how many observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```

Col means and SD
```{r}
round(colMeans(wisc.data), 1)
```

```{r}
round(apply(wisc.data, 2, sd), 1)
```


```{r}
wisc.pr<- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

#Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
44.3%
```{r}
summary(wisc.pr)
```


#Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
3- 72.6%

#Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
PC7

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis+1, xlab= "PC1", ylab= "PC2")
```

```{r}
biplot(wisc.pr)
```


#Repeat for component 1 and 3
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis+1, 
     xlab= "PC1", ylab= "PC3")
```

#variance 
```{r}
pr.var<- wisc.pr$sdev^2
head(pr.var)
```


Calculate the percentage variance explained by each principal component:
```{r}
pve<- (pr.var/sum(pr.var))*100
head(pve)
```

#Plotting variance for each principal component 
```{r}
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 100), type = "o")
```

```{r}
## Alternative scree plot of the same data, note data driven y-axis

barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
# Par lets you create side by side plot of the two graphs 
par(mfcol=c(1,2))

plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Percent of Variance Explained", 
     ylim = c(0, 100), type = "o")

plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 100), type = "o")
```

#Hierarchial Clustering 

```{r}
#Scaling data 
data.scaled<- scale(wisc.data)
```


#Calculating Euclidean distances between all pairs and observations 
```{r}
data.dist<- dist(wisc.data)
```

```{r}
wisc.hclust<- hclust(data.dist, method= "complete")
```

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=6)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```

#Q12. Can you find a better cluster vs diagnoses match with by cutting into a different number of clusters between 2 and 10?
```{r}
table(wisc.hclust.clusters, diagnosis)
```


#Clustering on PCA results

Using the minimum number of principal components required to describe at least 90% of the variability in the data
```{r}
wisc.pca.hcluster<- hclust( dist(wisc.pr$x[, 1:7]), method="ward.D2")
plot(wisc.pca.hcluster)
```

```{r}
grps<- cutree(wisc.pca.hcluster, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col= grps)
```
#Rgl 
```{r}

```



#Prediction 

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

Plot new patients on PCA plot from before 
```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
```











